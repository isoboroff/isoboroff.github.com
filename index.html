<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta charset="utf-8"><meta name="description" content="search, evaluation, social media, big data, and music"><meta name="author" content="Ian Soboroff"><title>In No Particular Order | In No Particular Order</title><link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css"><link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css"><link href="assets/css/rst.css" rel="stylesheet" type="text/css"><link href="assets/css/code.css" rel="stylesheet" type="text/css"><link href="assets/css/colorbox.css" rel="stylesheet" type="text/css"><link href="assets/css/theme.css" rel="stylesheet" type="text/css"><!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js" type="text/javascript"></script>
    <![endif]--><link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml"></head><body>
<!-- Menubar -->
<div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">

        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </a>

            <a class="brand" href=".">
            In No Particular Order
            </a>
            <!-- Everything you want hidden at 940px or less, place within here -->
            <div class="nav-collapse collapse">
                <ul class="nav"><li><a href="archive.html">Archives</a>
            </li><li><a href="categories/index.html">Tags</a>
            </li><li><a href="rss.xml">RSS</a>

                </li></ul><ul class="nav pull-right"></ul></div>
        </div>
    </div>
</div>
<!-- End of Menubar -->
<div class="container-fluid" id="container-fluid">
    <!--Body content-->
    <div class="row-fluid">
    <div class="span2"></div>
    <div class="span8">
    
        <div class="postbox">
        <h1><a href="posts/home-sweet-home.html">Home sweet home</a>
        <small>  
             Posted: <time class="published" datetime="2013-05-10T14:36:19-04:00">2013-05-10 14:36</time></small></h1>
        <hr><p>Since Posterous is going away real soon now, I needed to migrate my
old site from pseudo.posterous.com.  Well, 'need' is of course a
relative term, but the old site did have some posts on using ClueWeb
and HBase which some folks might still find useful.</p>
<p>It's nice that Posterous provided a way to bundle and download your
blog, but I decided to declare my independence (well, mostly) and move
the blog to a github pages site.  This way, the blog itself is
maintained in a git repository, and I can edit and push changes from
the command line.</p>
<p>After reading <a href="http://jakevdp.github.io/blog/2013/05/07/migrating-from-octopress-to-pelican/">this
post</a>
I spent some time reading up on static page generators and, after
playing with Jekyll-bootstrap and recoiling from its Ruby-ness (sorry, it's
just me), I settled on [Nikola][http://nikola.ralsina.com.ar/], which
is implemented in Python, a language I already speak.</p>
<p>A Posterous dump comes down basically in WordPress format, and Nikola
can import that.  The
<a href="http://nikola.ralsina.com.ar/handbook.html#importing-your-wordpress-site-into-nikola">instructions</a>
on that couldn't be simpler.</p>
<p>To work with github, I followed some advice from <a href="https://groups.google.com/forum/#!topic/nikola-discuss/aDbsPtu4pNc">this
thread</a>.
I created a branch called 'src', and in that branch set up a
virtualenv with Nikola and all the parts it wanted.  I then ported my
site, which created a directory 'new_site'.  'nikola build' went fine
after chasing down yet more Python packages for dates and Markdown.  I
then made a new clone of the git repository, copied the contents
of the 'output' directory, and committed that to the master branch.
Voila, everything in git and github.</p>
<p>This is really just a test post to see that everything's working.  If
it is, you can <a href="https://github.com/isoboroff/isoboroff.github.com/blob/src/new_site/conf.py">see my
conf.py</a>
which shows how its done.</p>
<p>PS. The Wordpress import has failed to understand a number of posts
containing code.  I am in the process of porting those old pages to
Markdown so they are actually usable again.  This has allowed me to
test deployment and it works awesomely.</p>
            
    <p>
        <a href="posts/home-sweet-home.html#disqus_thread" data-disqus-identifier="cache/posts/home-sweet-home.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/getting-large-collections-into-lucene-via-seq.html">Getting large collections into Lucene via SequenceFiles</a>
        <small>  
             Posted: <time class="published" datetime="2011-04-08T10:15:23-07:00">2011-04-08 10:15</time></small></h1>
        <hr><p>I had a problem while setting up my indexing job for the ClueWeb09 collection. I wanted to do it from a MapReduce job: take each document, break it down into indexable chunks (title, URL, metadata, text, anchors) keyed by URL, sort around to accumulate the anchors for each document, then dump to an IndexWriter writing to local storage in the reduce phase.</p>
<p>Great idea, only Lucene would get into long periods of juggling files in the FSDirectory, and the reduce jobs would time out. My cluster would run 36 reduce jobs, and each one at the end (using the different process I'm about to describe) produced a 55GB index of around 14 million documents. Maybe this was expected, maybe not.</p>
<p>So here's what I did instead: the indexable chunks are sorted down in the reduce phase and written out to LZO-compressed SequenceFiles. Here's how it works... this code is too closely tied up in our larger IR system to easily post the code up to a repository, so you'll have to make do with snippets and pseudocode this time around.</p>
<p>The Mapper job takes each document, parses out the headers, text, anchors, bacon, and coffee, and puts each one into what I call a ParseTuple. A ParseTuple is a (key, value) pair. Note that this is a simple WritableComparable.</p>
<div class="code"><pre><span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">IOException</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">DataInput</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">DataOutput</span><span class="p">;</span>

<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">Text</span><span class="p">;</span>
<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">WritableComparable</span><span class="p">;</span>

<span class="n">public</span> <span class="n">class</span> <span class="n">ParseTuple</span> <span class="n">implements</span> <span class="n">WritableComparable</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">ParseTuple</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="p">{</span>
    <span class="n">protected</span> <span class="n">String</span> <span class="n">label</span><span class="p">;</span>
    <span class="n">protected</span> <span class="n">String</span> <span class="n">data</span><span class="p">;</span>

    <span class="n">public</span> <span class="nf">ParseTuple</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">null</span><span class="p">;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">null</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="nf">ParseTuple</span><span class="p">(</span><span class="n">String</span> <span class="n">a</span><span class="p">,</span> <span class="n">String</span> <span class="n">b</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">b</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="p">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="n">Text</span><span class="p">.</span><span class="n">writeString</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">);</span>
        <span class="n">Text</span><span class="p">.</span><span class="n">writeString</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">data</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">void</span> <span class="n">readFields</span><span class="p">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">Text</span><span class="p">.</span><span class="n">readString</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">Text</span><span class="p">.</span><span class="n">readString</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="k">static</span> <span class="n">ParseTuple</span> <span class="n">read</span><span class="p">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="n">ParseTuple</span> <span class="n">pt</span> <span class="o">=</span> <span class="n">new</span> <span class="n">ParseTuple</span><span class="p">();</span>
        <span class="n">pt</span><span class="p">.</span><span class="n">readFields</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
        <span class="k">return</span> <span class="n">pt</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">int</span> <span class="n">compareTo</span><span class="p">(</span><span class="n">ParseTuple</span> <span class="n">other</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"ptext"</span><span class="p">))</span>
            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
        <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">other</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"ptext"</span><span class="p">))</span>
            <span class="k">return</span> <span class="mi">1</span><span class="p">;</span>
        <span class="k">else</span>
            <span class="k">return</span> <span class="n">label</span><span class="p">.</span><span class="n">compareTo</span><span class="p">(</span><span class="n">other</span><span class="p">.</span><span class="n">label</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="n">String</span> <span class="n">toString</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">new</span> <span class="n">String</span><span class="p">(</span><span class="n">label</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="n">data</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>The Mapper class as you know emits (key, value) pairs.  In this case, the mapper maps documents to (URL, ParseTuple) pairs.  The keys inside each ParseTuple are used to identify how I want each tuple indexed - what Lucene Field, essentially, the data should go into.</p>
<p>The Reducer is going to compile all the ParseTuples for a given URL into what I call a DocBits.  Again, it's a simple serializable Map, so that the reducer can emit a single value for each URL.  Here's DocBits:</p>
<div class="code"><pre><span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">IOException</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">DataInput</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">DataOutput</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">HashMap</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">Map</span><span class="p">;</span>

<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">Text</span><span class="p">;</span>
<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">Writable</span><span class="p">;</span>
<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">mapreduce</span><span class="p">.</span><span class="n">Reducer</span><span class="p">;</span>

<span class="n">public</span> <span class="n">class</span> <span class="n">DocBits</span> <span class="n">implements</span> <span class="n">Writable</span> <span class="p">{</span>
    <span class="n">protected</span> <span class="n">HashMap</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">map</span><span class="p">;</span>

    <span class="n">public</span> <span class="nf">DocBits</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">map</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HashMap</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">void</span> <span class="nf">add</span><span class="p">(</span><span class="n">String</span> <span class="n">k</span><span class="p">,</span> <span class="n">String</span> <span class="n">v</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">map</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">void</span> <span class="nf">add</span><span class="p">(</span><span class="n">ParseTuple</span> <span class="n">p</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">map</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">label</span><span class="p">,</span> <span class="n">p</span><span class="p">.</span><span class="n">data</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">public</span> <span class="kt">void</span> <span class="n">write</span><span class="p">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">Map</span><span class="p">.</span><span class="n">Entry</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">String</span><span class="p">,</span> <span class="n">String</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">e</span> <span class="o">:</span> <span class="n">map</span><span class="p">.</span><span class="n">entrySet</span><span class="p">())</span> <span class="p">{</span>
            <span class="n">Text</span><span class="p">.</span><span class="n">writeString</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">e</span><span class="p">.</span><span class="n">getKey</span><span class="p">());</span>
            <span class="n">Text</span><span class="p">.</span><span class="n">writeString</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">e</span><span class="p">.</span><span class="n">getValue</span><span class="p">());</span>
        <span class="p">}</span>
        <span class="n">Text</span><span class="p">.</span><span class="n">writeString</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s">"EOD"</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="n">public</span> <span class="kt">void</span> <span class="n">readFields</span><span class="p">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="k">while</span> <span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">String</span> <span class="n">k</span> <span class="o">=</span> <span class="n">Text</span><span class="p">.</span><span class="n">readString</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">k</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"EOD"</span><span class="p">))</span>
                <span class="k">break</span><span class="p">;</span>
            <span class="n">String</span> <span class="n">v</span> <span class="o">=</span> <span class="n">Text</span><span class="p">.</span><span class="n">readString</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
            <span class="n">map</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">public</span> <span class="k">static</span> <span class="n">DocBits</span> <span class="n">read</span><span class="p">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="p">)</span> <span class="n">throws</span> <span class="n">IOException</span> <span class="p">{</span>
        <span class="n">DocBits</span> <span class="n">db</span> <span class="o">=</span> <span class="n">new</span> <span class="n">DocBits</span><span class="p">();</span>
        <span class="n">db</span><span class="p">.</span><span class="n">readFields</span><span class="p">(</span><span class="n">in</span><span class="p">);</span>
        <span class="k">return</span> <span class="n">db</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>The Reducer is very simple:</p>
<div class="code"><pre><span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">IOException</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">Map</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">HashMap</span><span class="p">;</span>
<span class="n">import</span> <span class="n">java</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">regex</span><span class="p">.</span><span class="n">Pattern</span><span class="p">;</span>

<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">Text</span><span class="p">;</span>
<span class="n">import</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">mapreduce</span><span class="p">.</span><span class="n">Reducer</span><span class="p">;</span>

<span class="n">public</span> <span class="n">class</span> <span class="n">ReduceParseTuplesToDocBits</span>
    <span class="n">extends</span> <span class="n">Reducer</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">Text</span><span class="p">,</span> <span class="n">ParseTuple</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">DocBits</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="p">{</span>

    <span class="n">public</span> <span class="kt">void</span> <span class="n">reduce</span><span class="p">(</span><span class="n">Text</span> <span class="n">key</span><span class="p">,</span> <span class="n">Iterable</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="n">ParseTuple</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="n">values</span><span class="p">,</span> 
                       <span class="n">Context</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">throws</span> <span class="n">IOException</span><span class="p">,</span> <span class="n">InterruptedException</span> <span class="p">{</span>

        <span class="n">DocBits</span> <span class="n">doc</span> <span class="o">=</span> <span class="n">new</span> <span class="n">DocBits</span><span class="p">();</span>
        <span class="n">StringBuilder</span> <span class="n">anchors</span> <span class="o">=</span> <span class="n">new</span> <span class="n">StringBuilder</span><span class="p">(</span><span class="mi">65536</span><span class="p">);</span>
        <span class="n">StringBuilder</span> <span class="n">title</span> <span class="o">=</span> <span class="n">new</span> <span class="n">StringBuilder</span><span class="p">(</span><span class="mi">8096</span><span class="p">);</span>
        <span class="n">boolean</span> <span class="n">have_parsed_doc</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>

        <span class="n">doc</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s">"url"</span><span class="p">,</span> <span class="n">key</span><span class="p">.</span><span class="n">toString</span><span class="p">());</span>
        <span class="n">context</span><span class="p">.</span><span class="n">setStatus</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="n">toString</span><span class="p">());</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">ParseTuple</span> <span class="n">t</span><span class="o">:</span> <span class="n">values</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"ptext"</span><span class="p">))</span> <span class="p">{</span>
                <span class="n">doc</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s">"ptext"</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">data</span><span class="p">);</span>
                <span class="n">have_parsed_doc</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
            <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"title"</span><span class="p">))</span>
                <span class="n">title</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">data</span><span class="p">).</span><span class="n">append</span><span class="p">(</span><span class="s">" "</span><span class="p">);</span>
            <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">equals</span><span class="p">(</span><span class="s">"anchor"</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">anchors</span><span class="p">.</span><span class="n">length</span><span class="p">()</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="mi">65536</span><span class="p">)</span>
                <span class="n">anchors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">data</span><span class="p">).</span><span class="n">append</span><span class="p">(</span><span class="s">" "</span><span class="p">);</span>

            <span class="k">else</span>
                <span class="n">doc</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">t</span><span class="p">);</span>

            <span class="n">context</span><span class="p">.</span><span class="n">progress</span><span class="p">();</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">have_parsed_doc</span><span class="p">)</span> <span class="p">{</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">anchors</span><span class="p">.</span><span class="n">length</span><span class="p">()</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="mi">0</span><span class="p">)</span>
                <span class="n">doc</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s">"anchor"</span><span class="p">,</span> <span class="n">anchors</span><span class="p">.</span><span class="n">toString</span><span class="p">());</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">title</span><span class="p">.</span><span class="n">length</span><span class="p">()</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="mi">0</span><span class="p">)</span>
                <span class="n">doc</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="s">"title"</span><span class="p">,</span> <span class="n">title</span><span class="p">.</span><span class="n">toString</span><span class="p">());</span>

            <span class="n">context</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">doc</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>


<p>The reducer has to be a little clever, because the Mapper will emit anchortext for documents that aren't in the collection.  We could actually index that if we wanted to, but we don't, since our job is only to search within the collection.</p>
<p>The main class that runs the job sets up the Mapper, Reducer, and the compressed SequenceFile:</p>
<div class="code"><pre>   <span class="n">public</span> <span class="kt">int</span> <span class="nf">run</span><span class="p">(</span><span class="n">String</span><span class="p">[]</span> <span class="n">args</span><span class="p">)</span> <span class="n">throws</span> <span class="n">Exception</span> <span class="p">{</span>
        <span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="n">getConf</span><span class="p">();</span>

        <span class="n">Job</span> <span class="n">job</span> <span class="o">=</span> <span class="n">new</span> <span class="n">Job</span><span class="p">(</span><span class="n">conf</span><span class="p">,</span> <span class="s">"p3l.MapReduceIndexer"</span><span class="p">);</span>

        <span class="n">job</span><span class="p">.</span><span class="n">setJarByClass</span><span class="p">(</span><span class="n">this</span><span class="p">.</span><span class="n">getClass</span><span class="p">());</span>
        <span class="n">LOG</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Jar is "</span> <span class="o">+</span> <span class="n">job</span><span class="p">.</span><span class="n">getJar</span><span class="p">());</span>

        <span class="n">job</span><span class="p">.</span><span class="n">setMapperClass</span><span class="p">(</span><span class="n">MapWebDocToParseTuple</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>
        <span class="n">job</span><span class="p">.</span><span class="n">setMapOutputKeyClass</span><span class="p">(</span><span class="n">Text</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>
        <span class="n">job</span><span class="p">.</span><span class="n">setMapOutputValueClass</span><span class="p">(</span><span class="n">ParseTuple</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>

        <span class="n">job</span><span class="p">.</span><span class="n">setReducerClass</span><span class="p">(</span><span class="n">ReduceParseTuplesToDocBits</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>
        <span class="n">job</span><span class="p">.</span><span class="n">setOutputKeyClass</span><span class="p">(</span><span class="n">Text</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>
        <span class="n">job</span><span class="p">.</span><span class="n">setOutputValueClass</span><span class="p">(</span><span class="n">DocBits</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>

        <span class="n">job</span><span class="p">.</span><span class="n">setInputFormatClass</span><span class="p">(</span><span class="n">ClueWebInputFormat</span><span class="p">.</span><span class="n">class</span><span class="p">);</span> <span class="c1">// default</span>
        <span class="n">job</span><span class="p">.</span><span class="n">setOutputFormatClass</span><span class="p">(</span><span class="n">SequenceFileOutputFormat</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>

        <span class="n">FileInputFormat</span><span class="p">.</span><span class="n">setInputPaths</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">new</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]));</span>
        <span class="n">SequenceFileOutputFormat</span><span class="p">.</span><span class="n">setOutputPath</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">new</span> <span class="n">Path</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">]));</span>
        <span class="n">SequenceFileOutputFormat</span><span class="p">.</span><span class="n">setCompressOutput</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
        <span class="n">SequenceFileOutputFormat</span><span class="p">.</span><span class="n">setOutputCompressorClass</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">com</span><span class="p">.</span><span class="n">hadoop</span><span class="p">.</span><span class="n">compression</span><span class="p">.</span><span class="n">lzo</span><span class="p">.</span><span class="n">LzoCodec</span><span class="p">.</span><span class="n">class</span><span class="p">);</span>
        <span class="n">SequenceFileOutputFormat</span><span class="p">.</span><span class="n">setOutputCompressionType</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">SequenceFile</span><span class="p">.</span><span class="n">CompressionType</span><span class="p">.</span><span class="n">BLOCK</span><span class="p">);</span>

        <span class="c1">// job.submit();</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">job</span><span class="p">.</span><span class="n">waitForCompletion</span><span class="p">(</span><span class="nb">true</span><span class="p">)</span> <span class="o">?</span> <span class="mi">0</span> <span class="o">:</span> <span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
</pre></div>


<p>So at the end of this job, each Reducer has created a 26GB LZO-compressed SequenceFile ready to index:    </p>
<div class="code"><pre><span class="p">[</span><span class="n">soboroff</span><span class="err">@</span><span class="n">node1</span> <span class="o">~</span><span class="p">]</span><span class="err">$</span> <span class="n">hadoop</span> <span class="n">fs</span> <span class="o">-</span><span class="n">ls</span> <span class="n">clue</span>
<span class="n">Found</span> <span class="mi">38</span> <span class="n">items</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span>           <span class="mi">0</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">14</span><span class="o">:</span><span class="mi">09</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">_SUCCESS</span>
<span class="n">drwxrwxr</span><span class="o">-</span><span class="n">x</span>   <span class="o">-</span> <span class="n">soboroff</span> <span class="n">hadoop</span>           <span class="mi">0</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mo">07</span> <span class="mi">15</span><span class="o">:</span><span class="mi">38</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">_logs</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26327668533</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00000</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26339468375</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00001</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26330501868</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">17</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00002</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26366091781</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">14</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00003</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26321214072</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">16</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00004</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26349081494</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00005</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26343308176</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">28</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00006</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26352600382</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">24</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00007</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26321726649</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0000</span><span class="mi">8</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26339094476</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">10</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0000</span><span class="mi">9</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26321564045</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">16</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00010</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26343854112</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">10</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00011</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26315754762</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">15</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00012</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26346819081</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00013</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26364417290</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">10</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00014</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26345720864</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">15</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00015</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26325886676</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">19</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00016</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26352366823</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">16</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00017</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26363877289</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">10</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0001</span><span class="mi">8</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26346838673</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">23</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0001</span><span class="mi">9</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26334634232</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00020</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26338242486</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">15</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00021</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26333691832</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">11</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00022</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26351824723</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">13</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00023</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26340649075</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">14</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00024</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26348830107</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">11</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00025</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26341221269</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">17</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00026</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26318480301</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">09</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00027</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26314900021</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">22</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0002</span><span class="mi">8</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26335481459</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">16</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">0002</span><span class="mi">9</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26329189695</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">22</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00030</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26347416304</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">14</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00031</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26340982688</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">27</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00032</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26327061702</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">18</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00033</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26331125728</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">12</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00034</span>
<span class="o">-</span><span class="n">rw</span><span class="o">-</span><span class="n">r</span><span class="o">--</span><span class="n">r</span><span class="o">--</span>   <span class="mi">3</span> <span class="n">soboroff</span> <span class="n">hadoop</span> <span class="mi">26328859269</span> <span class="mi">2011</span><span class="o">-</span><span class="mo">02</span><span class="o">-</span><span class="mi">08</span> <span class="mi">08</span><span class="o">:</span><span class="mi">09</span> <span class="o">/</span><span class="n">user</span><span class="o">/</span><span class="n">soboroff</span><span class="o">/</span><span class="n">clue</span><span class="o">/</span><span class="n">part</span><span class="o">-</span><span class="n">r</span><span class="o">-</span><span class="mo">00035</span>
</pre></div>


<p>And lastly, I have a stand-alone application which uses a SequenceFile.Reader to read each DocBits and build it into a Lucene Document, which gets passed on to an IndexWriter.  This application doesn't run under MapReduce, so I don't worry about Lucene timeouts.  Also, I have the entire collection preparsed, so I can easily shove those bits into HBase or any other system I want to.</p>
            
    <p>
        <a href="posts/getting-large-collections-into-lucene-via-seq.html#disqus_thread" data-disqus-identifier="cache/posts/getting-large-collections-into-lucene-via-seq.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/benchmarking-lzo-compression-in-hbase.html">Benchmarking LZO compression in HBase</a>
        <small>  
             Posted: <time class="published" datetime="2011-01-06T12:10:00-08:00">2011-01-06 12:10</time></small></h1>
        <hr><p></p><p>This is continued from my last post, <a href="http://pseudo.posterous.com/getting-clueweb-into-hbase">Getting Clueweb Into HBase</a>.  Comments from that post suggested trying LZO compression.  This required code from <a href="https://github.com/kevinweil/hadoop-lzo">Kevin Weil and Todd Lipcon</a> that implements LZO compression for Hadoop that works with CDH3b3, which is what I'm running.  I won't cover configuring LZO with Hadoop and HBase, since this is well documented in the documentation on the github site.</p><p></p> I created a new table, 'webtable2', with the additional option COMPRESSION =&gt; 'lzo' for the 'content' column family.  That is, the webpage content will be compressed, but the mapping from document identifiers to URLs is left uncompressed.  There certainly isn't any reason not to compress the 'meta' family too, but at this point I primarily wanted to test fetching pages out by URL and this is all in the 'content' table.<p></p> I reloaded all of ClueWeb09 into webtable2.  In contrast to my experience with the first load, loads took a consistent 3-4 hours per batch, which is probably attributable to having gone to 4GB regions, so a lot less regionsplits were taking place.  The result:<p></p> <span style="font-family: courier new,monospace;">$ hadoop fs -du /hbase</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">Found 8 items</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">3409            hdfs://node1:9000/hbase/-ROOT-</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">35602480        hdfs://node1:9000/hbase/.META.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">0               hdfs://node1:9000/hbase/.corrupt</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">3542474         hdfs://node1:9000/hbase/.logs</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">0               hdfs://node1:9000/hbase/.oldlogs</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">3               hdfs://node1:9000/hbase/hbase.version</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">14955092829826  hdfs://node1:9000/hbase/webtable</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">2808802017826   hdfs://node1:9000/hbase/webtable2</span><p></p> The uncompressed webtable takes up 14.9TB on HDFS to store 12.5TB of text and about 50GB of URL-id mapping (not bad overhead at all).  The LZO version, however, only takes up 2.8TB.  Already a good reason to consider using compression.  Since I have all my HDFS blocks replicated three times, this is significant storage savings!<p></p> I then wrote a very simple benchmark, where a single client process makes requests with URLs and waits to receive each page:<p></p><span style="font-family: courier new,monospace;">public class Bench {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    public static void main(String args[]) throws Exception {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    if (args.length != 2) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        System.out.println("Usage: Bench [table] [inputfile]");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        System.exit(-1);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    Configuration config = HBaseConfiguration.create();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    HTable table = new HTable(config, args[0]);</span><p></p><span style="font-family: courier new,monospace;">    BufferedReader in = new BufferedReader(new FileReader(args[1]));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    String query = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    long c_count = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    long m_count = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    long start = System.currentTimeMillis();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    long last = start;</span><p></p><span style="font-family: courier new,monospace;">    while ((query = in.readLine()) != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        if (query.startsWith("http://")) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            query = Util.reverse_hostname(query);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        } else if (query.startsWith("clueweb")) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            Get g = new Get(Bytes.toBytes(query));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            Result r = table.get(g);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            byte[] value = r.getValue(Bytes.toBytes("meta"),</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                          Bytes.toBytes("url"));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            query = Bytes.toString(value);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            m_count++;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Get g = new Get(Bytes.toBytes(query));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Result r = table.get(g);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        byte[] value = r.getValue(Bytes.toBytes("content"), </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                      Bytes.toBytes("raw"));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        c_count++;</span><p></p><span style="font-family: courier new,monospace;">        if ((c_count % 10000) == 0) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            long now = System.currentTimeMillis();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            double sec = (now - last) / 1000.0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            double rate = sec / 10000.0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            System.out.println("("+c_count+") 10,000 queries in " +</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                       sec + "s (" + rate + " s/q)");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            last = System.currentTimeMillis();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                       </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        } catch (IOException e) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            continue;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p> <span style="font-family: courier new,monospace;">    long end = System.currentTimeMillis();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    System.out.println("Fetched " + c_count + " content records.");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    if (m_count &gt; 0) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        System.out.println("Fetched " + m_count + " meta records.");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    System.out.println("Total time: " + (end - start) / 1000.0 + "s");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    System.out.println("Time per fetch: " </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">               + ((end - start) / ((c_count + m_count) * 1000.0))</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">               + "s");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">}</span><p></p>This class reads URLs from a file to fetch.  The benchmark isn't measuring peak query response rate, since to do that it would make more sense to have lots of clients asking simultaneously.  However, it does measure a reasonable rate of requests to see if response times are sufficient and that we don't leak memory or anything else.  (My usage scenario only has perhaps a few dozen users.)<p></p> I took a sample of 500,000 URLs from the collection to use for testing.  Before running, I shut down HBase (master and region server processes) and started them up again.  (I neglected to shut down HDFS as well, perhaps I should have.)  First, running against the uncompressed table and printing timing information after every 10k requests:<p></p> <span style="font-family: courier new,monospace;">(10000) 10,000 queries in 2936.995s (0.2936995 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(20000) 10,000 queries in 2723.424s (0.2723424 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(30000) 10,000 queries in 1781.611s (0.17816110000000002 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(40000) 10,000 queries in 774.718s (0.0774718 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(50000) 10,000 queries in 844.356s (0.0844356 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(60000) 10,000 queries in 1300.254s (0.13002539999999999 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(70000) 10,000 queries in 1276.55s (0.127655 s/q)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(80000) 10,000 queries in 1261.369s (0.1261369 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(90000) 10,000 queries in 1207.213s (0.12072129999999999 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(100000) 10,000 queries in 1206.334s (0.1206334 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(110000) 10,000 queries in 1404.424s (0.1404424 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(120000) 10,000 queries in 1209.425s (0.1209425 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(130000) 10,000 queries in 1137.359s (0.11373589999999999 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(140000) 10,000 queries in 800.359s (0.08003590000000001 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(150000) 10,000 queries in 943.502s (0.0943502 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(160000) 10,000 queries in 724.696s (0.07246960000000001 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(170000) 10,000 queries in 975.958s (0.0975958 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">...<p></p></span>The times seem to hover around 1/10s per query, which is perfectly reasonable for my usage scenario.  (If it wasn't, the thing to do is to spread the regions across more regionservers.  There is also a request bottleneck at the .META. table which is an HBase limitation.)  There is also a lot of variation in time between batches, with the shortest average 0.077s/q and the longest 0.29s/q.  It doesn't get shorter consistently through the run, so caching is not helping beyond a certain point... there are simply too many regions to cache efficiently.  System load on the cluster nodes was not an issue at all.<p></p> Now, here is timing of the same sequence of fetches (on a clean startup of HBase) against the compressed webtable:<p></p><span style="font-family: courier new,monospace;">(10000) 10,000 queries in 561.779s (0.0561779 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(20000) 10,000 queries in 484.254s (0.0484254 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(30000) 10,000 queries in 512.418s (0.051241800000000004 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(40000) 10,000 queries in 514.108s (0.05141079999999999 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(50000) 10,000 queries in 515.848s (0.05158479999999999 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(60000) 10,000 queries in 513.325s (0.0513325 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(70000) 10,000 queries in 456.037s (0.0456037 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(80000) 10,000 queries in 472.251s (0.0472251 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(90000) 10,000 queries in 459.83s (0.045982999999999996 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(100000) 10,000 queries in 488.919s (0.048891899999999995 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(110000) 10,000 queries in 485.988s (0.0485988 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(120000) 10,000 queries in 468.895s (0.0468895 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(130000) 10,000 queries in 485.07s (0.048507 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(140000) 10,000 queries in 488.118s (0.0488118 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(150000) 10,000 queries in 480.102s (0.048010199999999996 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(160000) 10,000 queries in 461.39s (0.046139 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">(170000) 10,000 queries in 509.506s (0.0509506 </span><span style="font-family: courier new,monospace;">s/q</span><span style="font-family: courier new,monospace;">)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">...<p></p></span>With compression, query batches average twice as fast to complete, and also those times are much more consistent.  Compressing takes 20% of the space in HDFS (before replication) and provides much faster query response times.  Win!
            
    <p>
        <a href="posts/benchmarking-lzo-compression-in-hbase.html#disqus_thread" data-disqus-identifier="cache/posts/benchmarking-lzo-compression-in-hbase.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/getting-clueweb-into-hbase.html">Getting Clueweb into HBase</a>
        <small>  
             Posted: <time class="published" datetime="2010-12-21T08:46:00-08:00">2010-12-21 08:46</time></small></h1>
        <hr><p></p><p>I have a simple webtable in <a href="http://hbase.apache.org/">HBase</a> to hold the <a href="http://boston.lti.cs.cmu.edu/Data/clueweb09/">Clueweb09</a> collection.  The english portion of Clueweb09 is around 500 million web pages or 12.5TB of data.  I recommend reading the above link for details on Clueweb09; in <a href="http://trec.nist.gov/">TREC</a>, we are using it in several tracks focusing on different aspects of web search.</p><p></p> I wanted to put Clueweb into HBase to make it easy to fetch individual web pages from the collection and show them to a user, who then analyzes the web page and determines if it is relevant to some search topic.  We have an existing method for this, but it doesn't scale to large collections.  My simple webtable has the following structure:<p></p> <span style="font-family: courier new,monospace;">hbase(main):002:0&gt; create 'webtable', {NAME =&gt; 'content', BLOCKSIZE =&gt; '1048576'}, 'meta'</span><p></p>That is, two column families: 'content' and 'meta'.  Content maps a url to the web page content.  Meta is for general metadata, but at the moment it just maps the internal Clueweb document identifiers to the corresponding url.  Using this structure, I can retrieve documents either by url or by document identifier, and support fetching individual documents as well as browsing within the collection.  The content content family has a larger blocksize (1MB), but otherwise there are no changes from the stock table settings.<p></p> My cluster is fairly small in terms of cores and memory, but large on storage.  I have 14 physical nodes, each with 8 cores, 8GB of RAM, and 12.5TB of storage disk in seven spindles.  The first node is the NameNode, JobTracker, and HBase master, and has its storage striped into a RAID-5.  The second node mirrors the namenode storage, and also acts as the SecondaryNameNode.  The remaining twelve nodes keep the seven data disks separate, and each run a DataNode, TaskTracker, and RegionServer.  I'm running Cloudera's CDH3 beta (737) on top of CentOS-5.<p></p> For Hadoop's configuration, I have HDFS replicating each block to three locations.  The processes on the NN get more heap, but on the workers, heap is limited to 1GB per process.  I use the FairScheduler and allow 3 mappers and 3 reducers to run on each host.  <p></p> For HBase, I started with a region filesize of 2GB.  I based this on estimating that I wanted around 500 regions per node once all the data was loaded, and 500 * 2GB * 12 equals around 12.5TB.  Later on as I was loading data, I found that I was getting more than 700 regions per node and timeouts during put calls, so I bumped the region max to 4GB, and added an hbase.client.pause of 5000 (5ms).<p></p> I split the collection into ten pieces, so I could load it a piece at a time and start over when I needed to.  At the beginning, I loaded 1.25TB of text in 4 hours.  As more and more data was loaded, this crept up to 8 hours.  I think the time would have been kept lower overall if I'd started with 4GB regions, rather than loading nearly all the data with 2GB regions and bumping it up near the end.<p></p> Now, some code.  Below I'm including snippets; you can find the full source code at <a href="https://github.com/isoboroff/clueweb-hbase">https://github.com/isoboroff/clueweb-hbase</a>.  First is an input format for reading the ClueWeb documents.  It has some helpful machinery for traversing directories, but its basic job is to read a single WARC entry at a time and return it as a String.<p></p> <br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">public class ClueWebInputFormat extends FileInputFormat&lt;LongWritable, Text&gt; {</span><p></p> <span style="font-family: courier new,monospace;">    public static final Log LOG =</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        LogFactory.getLog(ClueWebInputFormat.class);</span><p></p> <span style="font-family: courier new,monospace;">    @Override</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    public boolean isSplitable(JobContext job, Path filename) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        return false;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    @Override </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    public RecordReader&lt;LongWritable, Text&gt; </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        createRecordReader(InputSplit split, TaskAttemptContext context)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        ClueWebRecordReader rr = new ClueWebRecordReader();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        rr.initialize(split, context);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        return rr;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p><span style="font-family: courier new,monospace;">   </span><span style="font-family: courier new,monospace;"> public static class ClueWebRecordReader </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        extends RecordReader&lt;LongWritable, Text&gt; {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private long start;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private long end;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private long pos;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private Path path;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private LineRecordReader in;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private LongWritable cur_key = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private Text cur_val = null;</span><p></p> <span style="font-family: courier new,monospace;">        public ClueWebRecordReader() {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            </span><p></p><span style="font-family: courier new,monospace;">        public void initialize(InputSplit split, TaskAttemptContext context)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            cur_key = new LongWritable(0);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (split instanceof FileSplit) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    path = ((FileSplit)split).getPath();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                } else {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    path = new Path("");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                start = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                pos = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                end = split.getLength();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                in = new LineRecordReader();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                in.initialize(split, context);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            } catch (InterruptedException ie) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                throw new IOException(ie);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        public LongWritable getCurrentKey() { </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            return cur_key;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        public Text getCurrentValue() { </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            return cur_val; </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><p></p> <span style="font-family: courier new,monospace;">        private Text hold = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private long last_pos = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        StringBuilder buf = null;</span><p></p><span style="font-family: courier new,monospace;">        public synchronized boolean nextKeyValue() </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            Text line = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            cur_val = new Text();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            boolean in_doc = false;</span><p></p> <span style="font-family: courier new,monospace;">            if (buf == null)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                buf = new StringBuilder();</span><p></p> <span style="font-family: courier new,monospace;">            if (hold != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                buf.append(hold.toString()).append("\n");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                hold = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                in_doc = true;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                while (in.nextKeyValue()) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    line = in.getCurrentValue();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    int size = line.getLength();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    last_pos = pos;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    pos += size;</span><p></p> <span style="font-family: courier new,monospace;">                    if (line.find("WARC/0.18") == 0) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                        if (in_doc) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                            in_doc = false;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                            hold = line;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                            break;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                        } else {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                            in_doc = true;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                            continue;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    }</span><p></p> <span style="font-family: courier new,monospace;">                    if (in_doc)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                        buf.append(line.toString()).append("\n");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            } catch (java.io.IOException e) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><p></p><span style="font-family: courier new,monospace;">            if (buf.length() &gt; 0) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                cur_val.set(buf.toString());</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                cur_key.set(cur_key.get() + 1);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                buf = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                return true;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            } else {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                LOG.info("nkv returning false");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                return false;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><p></p><span style="font-family: courier new,monospace;">        public float getProgress() {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            return Math.min(1.0f, (pos) / (float)(end));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><p></p> <span style="font-family: courier new,monospace;">        public synchronized void close() throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            if (in != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                in.close();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">}</span><p>Next is the MapReduce class to load the data.  This is adapted from example code that comes with HBase.</p><p><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">public class LoadClue {</span></p><p></p> <span style="font-family: courier new,monospace;">    private static final String NAME = "LoadClue";</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">  </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    private static String reverse_hostname(String uri) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        URL url = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            url = new URL(uri);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        } catch (MalformedURLException mue) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            return null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        String host = url.getHost();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        StringBuilder newhost = new StringBuilder();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        String[] parts = host.split("\.", 0);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        for (int i = parts.length - 1; i &gt; 0; i--) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            if (i &gt; 0)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                newhost.append(parts[i]).append(".");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        newhost.append(parts[0]);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        int port = url.getPort();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        if (port != -1)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            newhost.append(":").append(port);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        newhost.append(url.getFile());</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        return newhost.toString();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p><span style="font-family: courier new,monospace;">    private static HashMap&lt;String, String&gt; get_headers(String doc) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        HashMap&lt;String, String&gt; hdr = new HashMap(20);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            BufferedReader in = new BufferedReader(new StringReader(doc));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            int nl = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            String line = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            while ((line = in.readLine()) != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (line.length() == 0)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    nl++;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (nl == 2)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    break;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                int i = line.indexOf(':');</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (i == -1)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    continue;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    hdr.put(line.substring(0, i), line.substring(i+2));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                } catch (Exception e) {}</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            StringBuilder buf = new StringBuilder();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            while ((line = in.readLine()) != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                buf.append(line).append('\n');</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            hdr.put("document", buf.toString());</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        } catch (IOException e) {}</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        return hdr;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p><span style="font-family: courier new,monospace;">    protected static String table_name = null;</span><p></p> <span style="font-family: courier new,monospace;">    protected static void setTableName(String n) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        table_name = n;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p><span style="font-family: courier new,monospace;">    static class Uploader </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        extends Mapper&lt;LongWritable, Text, ImmutableBytesWritable, Put&gt; {</span><p></p> <span style="font-family: courier new,monospace;">        private long checkpoint = 1000;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        private long count = 0;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        @Override</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            public void map(LongWritable key, Text value, Context context)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            throws IOException {</span><p></p> <span style="font-family: courier new,monospace;">            String raw = value.toString();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            HashMap&lt;String, String&gt; parse = get_headers(raw);</span><p></p> <span style="font-family: courier new,monospace;">            if (parse.get("WARC-Type").equals("response")) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                String uri = parse.get("WARC-Target-URI");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (uri == null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    System.err.println("Doc has no target-uri");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    return;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                String keystr = reverse_hostname(uri);</span><p></p> <span style="font-family: courier new,monospace;">                byte[] row = Bytes.toBytes(keystr);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                byte[] family = Bytes.toBytes("content");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                byte[] qualifier = Bytes.toBytes("raw");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                byte[] val = Bytes.toBytes(parse.get("document"));</span><p></p> <span style="font-family: courier new,monospace;">                // Create Put</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                Put put = new Put(row);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                put.add(family, qualifier, val);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">      </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                // Uncomment below to disable WAL. This will improve</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                // performance but means you will experience data loss in</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                // the case of a RegionServer crash.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                put.setWriteToWAL(false);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                String trecid = parse.get("WARC-TREC-ID");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                byte[] row2 = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                Put put2 = null;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if (trecid != null) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    row2 = Bytes.toBytes(parse.get("WARC-TREC-ID"));</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    put2 = new Put(row2);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    byte[] fam2 = Bytes.toBytes("meta");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    byte[] qual2 = Bytes.toBytes("url");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    byte[] val2 = row;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    put2.add(fam2, qual2, val2);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    put2.setWriteToWAL(false);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><p></p><span style="font-family: courier new,monospace;">                try {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    context.write(new ImmutableBytesWritable(row), put);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    if (trecid != null)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                        context.write(new ImmutableBytesWritable(row2), put2);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                } catch (InterruptedException e) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    e.printStackTrace();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                // Set status every checkpoint lines</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                if(++count % checkpoint == 0) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                    context.setStatus("Emitting doc " + count);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><p></p><span style="font-family: courier new,monospace;">        @Override </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            public void cleanup(Context context) </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            if (LoadClue2.table_name == null)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">                return;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            context.setStatus("Sending flush");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            HBaseAdmin admin = new HBaseAdmin(context.getConfiguration());</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            admin.flush(LoadClue2.table_name);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">  </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    /<strong></strong></span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     * Job configuration.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     */</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    public static Job configureJob(Configuration conf, String [] args)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        throws IOException {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Path inputPath = new Path(args[0]);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        String tableName = args[1];</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Job job = new Job(conf, NAME + "_" + tableName);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        job.setJarByClass(Uploader.class);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        FileInputFormat.setInputPaths(job, inputPath);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        job.setInputFormatClass(ClueWebInputFormat.class);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        job.setMapperClass(Uploader.class);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        LoadClue2.setTableName(tableName);</span><p></p> <span style="font-family: courier new,monospace;">        // No reducers.  Just write straight to table.  Call initTableReducerJob</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        // because it sets up the TableOutputFormat.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        TableMapReduceUtil.initTableReducerJob(tableName, null, job);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        TableMapReduceUtil.addDependencyJars(conf, TableOutputFormat.class);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        job.setNumReduceTasks(0);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        return job;</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><p></p> <span style="font-family: courier new,monospace;">    /</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     * Main entry point.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     * </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     * @param args  The command line parameters.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     * @throws Exception When running the job fails.</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">     */</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    public static void main(String[] args) throws Exception {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Configuration conf = HBaseConfiguration.create();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        if(otherArgs.length != 2) {</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            System.err.println("Wrong number of arguments: " + otherArgs.length);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            System.err.println("Usage: " + NAME + " &lt;input&gt; &lt;tablename&gt;");</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">            System.exit(-1);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        Job job = configureJob(conf, otherArgs);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        boolean result = job.waitForCompletion(true);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        System.out.println("Flushing table " + otherArgs[1]);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        HBaseAdmin admin = new HBaseAdmin(conf);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        admin.flush(otherArgs[1]);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">        System.exit((result == true) ? 0 : 1);</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">    }</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">}</span>
            
    <p>
        <a href="posts/getting-clueweb-into-hbase.html#disqus_thread" data-disqus-identifier="cache/posts/getting-clueweb-into-hbase.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/the-ladder-of-user-tracking-and-privacy.html">The ladder of user tracking and privacy</a>
        <small>  
             Posted: <time class="published" datetime="2010-12-16T12:25:25-08:00">2010-12-16 12:25</time></small></h1>
        <hr><p>Privacy and behavior tracking by websites and web-connected products has long been a concern of privacy advocates and some in the technical sphere.  Recent events prodded me to compose this post to assemble my thoughts on the matter.  Those events include a <a href="http://www.washingtonpost.com/wp-dyn/content/article/2010/12/15/AR2010121506581.html">decision by the courts</a> that hosted email is protected under the Fourth Amendment; a <a href="http://www.npr.org/2010/12/15/132058735/is-your-e-book-reading-up-on-you">story on NPR</a> that ebook readers collect and transmit usage data; the emergence of <a href="https://joindiaspora.com/">Diaspora</a>, a Facebook alternative, into alpha testing; and concerns over electronic voting.  These thoughts are mine and do not represent my employer in any way.</p>
<p>As active participants in a digital society, we are the key ingredient in online services and connected products, providing the entire revenue stream through our behavior.  However, we otherwise cannot participate in the market created by digital behavior tracking.  We have little awareness of what data is collected, no control over how that data is used, and no method of controlling it.  This is because the company or entity doing the tracking owns that data.  I'd like to propose that since we ourselves create that data, we should be able to participate in the process whereby that data is used.</p>
<p>Currently, privacy and tracking are modulated through privacy policies.  Such a policy aims to inform you, the user, about what data is collected and how it might be used.  Privacy policies have several problems.  They are written by lawyers, and as such may be hard for users to understand.  The policy provides the user no leverage aside from deciding not to use the service.  The user cannot determine that the policy is being honored.  The policy may be vague about what is actually collected and how actually that may be used or sold, and there is no avenue for a user to learn more.  If the policy is violated and the user learns about it, avenues for redress are few, expensive, and largely untested.</p>
<p>What is the cost of a privacy breach? If it results in actual identity theft, then actual damages may be calculable.  However, there may be other breaches and other costs whose damage may be harder to assess.  On the other side, how much is your behavior worth? Personal information has definite value both in isolation and in aggregate, to the user, to the collector, and to third parties.</p>
<p>I propose the following 8-step ladder of user tracking.  At each step of the ladder is a question for you to answer regarding an online service such as Facebook or a connected product such as a Kindle.  At the point of the ladder where the answer is "no" or "I don't know", you stop.</p>
<ol><li>Do you know that the site/company/product tracks your use?</li>
<li>Can you determine when tracking is occurring?</li>
<li>Do you know what activities are tracked?</li>
<li>How is your tracked usage being used by the site/company/product?</li>
<li>How is your usage used by others?</li>
<li>Can you obtain your usage data from the site/company/product?</li>
<li>Can you dictate whether or not your usage data is used?</li>
<li>Can you license how your usage data is used?</li>
</ol><p>Something I've specifically not included on the ladder is knowing how your tracked data is stored, and how secure that storage is.  I don't think this should even be on the ladder.  If a company holds my personal information but in an insecure environment, they should be fully liable for damage to me by their negligence.  If a company hews to best practices in information security, and are nonetheless hacked and my personal data stolen, that sounds to me like a risk that companies can insure against.  But secure storage of personal information is too fundamental to be placed on my ladder.</p>
<p>Level 1 is basic, and you might assume the answer is "yes", but rather than assuming, take time to see if you can figure out what's happening.  Your web browser should let you look through the cookies stored in it, so you can see if the site has placed any there.  If so, you should assume at least your presence on that site is being tracked by that site.  For devices such as a Kindle, a good approach is to connect over wifi, and use your home router to watch if it calls home, and how often.</p>
<p>Level 2, "Can you determine when tracking is occurring", might become apparent during investigation of level 1.  For example, if you find a cookie for a site, you should know that this cookie is sent to that host with every HTTP request to that host.  Additionally, once a site is loaded, Javascript code in the webpage can make HTTP requests behind the scenes, so the cookie may be read much more often than you click on things.  The geeks among us can enable certain things in the operating system or on our routers to watch these accesses, but most firewall tools aimed towards "regular users" are so intrusive they're hard to leverage for this problem.</p>
<p>Level 3 is "Do you know what activities are tracked".  A privacy policy may give some detail on this, but you can't verify that against the actual application; usually the policy is written broadly enough that it doesn't have to be modified for every new application feature.  When a site tries to connect to your Facebook account, it makes a claim to you as to what information that application will use; for example, if I enable Posterous' FB autoposting, Posterous can not only update my status when I post to my blog, it apparently gets permission to access my FB account even at other times.  Again, the claim is not verifiable, but it's nice that FB does this.</p>
<p>Above level 3 we are into territory which no current online service or connected device can lay claim.  A level 4 service would tell us how our usage and behavior data are being used.  I don't mean in a nebulous "improving the product experience" way, but actually report on when usage data is used or mined and for what purpose.</p>
<p>Stop and imagine that for a moment.  Imagine that you could actually know specifically how your tracked behaviors were being used.  You might decide that you approve of that usage, that you consider the outcome to be to your benefit as a customer.  Or you might not.  Right now, you just don't know, and that's the primary concern of privacy advocates.</p>
<p>Level 5 takes us beyond the site of concern, to other sites that our data is either shared with or sold to.  At present, we don't know if that data is used in aggregate or in a personally-identifiable way.  A privacy policy typically allows the site to share or sell usage data, but when that happens, we now have even less connection to that data.</p>
<p>Level 6 asks if we can obtain our tracked data from the site in question.  This idea is somewhat similar to how Facebook allows you to download your profile, posts, and friend connections, but specifically refers to tracked usage data.  This idea, to me, actually seems the most straightforward notion that might exist in the debate on online privacy -- that you, the user, should at least know what the company or site or product knows about you.</p>
<p>Level 7 asks, "Can you dictate whether or not your usage data is used."  Some might rather place this lower on the ladder, but I think that's counterproductive for all participants.  If you don't know what's being collected and tracked, you can't make an informed choice about whether to participate in that.  Moreover, the current implementation from the users perspective requires high levels of vigilance and might not be reliable.  However, if we arrive at level 7 after the first 6 levels, then we can have a constructive discussion about whether or not our personal data is used.</p>
<p>Level 8 is where I began thinking about this problem.  Usage data exists in a very active market, but we, the creators of that data, can't participate in that market.  Imagine that you own your behavioral data; you created it, so by some notion along the lines of copyright, you should in some fashion be considered its owner.  "Wait," you say, "we enact those behaviors within a system or with a device, so really it should be joint ownership, right?"  Hey, that would be great.  If I and Facebook own my data in partnership, we now have a whole new framework for discussing how it should be used.  And that framework is licensing.</p>
<p>Perhaps you're an open-source kind of fellow.  You might decide to license your behavior along a Creative-Commons style agreement, which protects your ownership and still requires that you have access through all levels of the ladder to your own data.  Or perhaps like most of us, you'd like to choose who to share your information with.  With licensing, that framework exists.</p>
<p>Me, I'm happy to share my personal information and behavior, provided I have a share in its income.  Think micropayments.  Mechanical Turk, turned on its head.  Come on, Google, let's make a deal.</p>
            
    <p>
        <a href="posts/the-ladder-of-user-tracking-and-privacy.html#disqus_thread" data-disqus-identifier="cache/posts/the-ladder-of-user-tracking-and-privacy.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/a-simple-gardenhose-catcher.html">A simple gardenhose catcher</a>
        <small>  
             Posted: <time class="published" datetime="2010-11-03T05:53:59-07:00">2010-11-03 05:53</time></small></h1>
        <hr><p></p><p>I wanted a simple script to pull tweets from Twitter's gardenhose feed (the "sample API", as it's now called) and dump it in files, but couldn't find exactly what I needed online.?? Below is a tweak of the "spritz.py" example from the <a href="https://github.com/atl/twitstream">twitstream</a> Python library.?? Posting in case someone else finds it useful.</p><p></p> <br><span style="font-family: courier new,monospace;">#!/usr/bin/env python26</span><p></p><span style="font-family: courier new,monospace;"># The key module provided here:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">import twitstream</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">from time import strftime, localtime</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">import json</span><p></p><span style="font-family: courier new,monospace;"># Provide documentation:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">USAGE = """%prog [options] </span><p></p><span style="font-family: courier new,monospace;">Show a real-time subset of all twitter statuses."""</span><p></p> <span style="font-family: courier new,monospace;"># Define a function/callable called on every status:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">class Store(object):</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? def <strong>init</strong>(self):</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? t = localtime()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? self.cur_hr = t.tm_hour</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? self.cur_out = open(strftime("output.%d-%m-%y.%H", t), "w")</span><p></p> <span style="font-family: courier new,monospace;">?????? def <strong>call</strong>(self, status):</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? t = localtime()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? if (t.tm_hour != self.cur_hr):</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????????????? if (not self.cur_out.closed):</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????????????????????? self.cur_out.close()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????????????? self.cur_hr = t.tm_hour</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????????????? self.cur_out = open(strftime("output.%d-%m-%y.%H", localtime()), "w")</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? json.dump(status, self.cur_out)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? self.cur_out.write("\n")</span><p></p> <span style="font-family: courier new,monospace;">if <strong>name</strong> == '<strong>main</strong>':</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? # Inherit the built in parser and use it to get credentials:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? parser = twitstream.parser</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? parser.usage = USAGE</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? (options, args) = parser.parse_args()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? twitstream.ensure_credentials(options)</span><p></p> <span style="font-family: courier new,monospace;">?????? cb = Store()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? # Call a specific API method in the twitstream module: </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? stream = twitstream.spritzer(options.username, options.password, cb, </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">???????????????????????????????????????????????????????????????? debug=options.debug, engine=options.engine)</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? </span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? # Loop forever on the streaming call:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? try:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? stream.run()</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????? finally:</span><br style="font-family: courier new,monospace;"><span style="font-family: courier new,monospace;">?????????????? cb.cur_out.close()</span>
            
    <p>
        <a href="posts/a-simple-gardenhose-catcher.html#disqus_thread" data-disqus-identifier="cache/posts/a-simple-gardenhose-catcher.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/xfsrepair-and-immense-filesystems.html">xfs_repair and immense filesystems</a>
        <small>  
             Posted: <time class="published" datetime="2010-10-18T07:49:14-07:00">2010-10-18 07:49</time></small></h1>
        <hr><p></p><p>Just a quickie here.?? If you have a ginormous XFS filesystem, xfs_check may report "out of memory" and xfs_repair may churn with 100% CPU during phase 6 ("traversing filesystem").</p><p></p>The answer is to not use xfs_check, but instead do "xfs_repair -n".?? Also, add the "-P -o bsize=1024" options.?? Then keep an eye on xfs_repair's %CPU in top(1).?? If it starts churning at 99% or 100%, then kill it and bump the bsize larger.<p></p> I had one filesystem I had to boost bsize to 10240 and isize to 4096 before it would make it through the scan.<p></p> Caveat -- this was on a NAS box running a variant of RHEL4.?? I was using xfs_repair v2.9.8, which was the latest I could find without cooking up a complete RHEL4 build environment.?? It's possible the XFS folks have fixed this one in a more recent version.
            
    <p>
        <a href="posts/xfsrepair-and-immense-filesystems.html#disqus_thread" data-disqus-identifier="cache/posts/xfsrepair-and-immense-filesystems.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/victor-wooten-and-jd-blair-at-the-birchmere-1.html">Victor Wooten and JD Blair at the Birchmere, 13 October 2010</a>
        <small>  
             Posted: <time class="published" datetime="2010-10-14T06:53:41-07:00">2010-10-14 06:53</time></small></h1>
        <hr><p></p><p>I went to this show last night with my father.?? In a word, the performance was astounding.?? The set opened with a jam between <a href="http://www.victorwooten.com/">Victor</a> and JD, then moved into "Me and My Bass Guitar".?? Several of Victor's children (ages 7, 9, and 12) performed with him on vocals and drums for a few songs, including an India.Arie cover and an original song by his daughter.?? Also appearing were bassist and local teacher extraordinaire <a href="http://www.bassology.net/">Anthony Wellington</a>, and his student Cole Sipe (somebody please correct my spelling if I mangled it!).?? Vic played an extended solo set including Amazing Grace, Norwegian Wood, The Lesson, and a lot of incredible loop pedal work.?? The closer was "U Can't Hold No Groove (If You Ain't Got No Pocket)".</p><p></p> Victor also shared lots of thoughts on music education, music as a language, and relationships between people of all types and backgrounds.?? He is always worth listening to.?? A good (and free) start is his visit to NPR's <a href="http://www.npr.org/templates/story/story.php?storyId=130514374">Talk of the Nation two days ago</a>.?? I am always energized and inspired when I listen to him play (especially live!).<p></p> Thanks, Victor (and all).<p></p> <p></p><div class="p_embed p_image_embed"><a href="http://getfile0.posterous.com/getfile/files.posterous.com/pseudo/AFIotr6fsfo0QioU441ksxBCav1QBRuQbcoZo6OJM4DMO0iYiIUw3qSNFoSK/2010-10-13_22-36-29_714.jpg.scaled.1000.jpg"><img alt="2010-10-13_22-36-29_714" height="282" src="http://getfile9.posterous.com/getfile/files.posterous.com/pseudo/fZmmhTlhdLtI7u9prJHjWhnwnUewO7CvaT9rvpnQTXlheUz2BEhhnjwl9Mfy/2010-10-13_22-36-29_714.jpg.scaled.500.jpg" width="500"></a><a href="http://getfile5.posterous.com/getfile/files.posterous.com/pseudo/tKkLRO0mBS1nuKQJvkCTPxm5tclibX6YB9ZJ1sxRmo0UhVzmli7EkjDnut9y/2010-10-13_22-39-21_208.jpg.scaled.1000.jpg"><img alt="2010-10-13_22-39-21_208" height="282" src="http://getfile4.posterous.com/getfile/files.posterous.com/pseudo/JqDNRVcy5r7aC9ki04xEihB9rILWBnaLQ29SBGByqDk8D1Jesz0PcTW4mE6c/2010-10-13_22-39-21_208.jpg.scaled.500.jpg" width="500"></a></div>
            
    <p>
        <a href="posts/victor-wooten-and-jd-blair-at-the-birchmere-1.html#disqus_thread" data-disqus-identifier="cache/posts/victor-wooten-and-jd-blair-at-the-birchmere-1.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/storing-and-processing-big-data.html">Storing and processing Big Data</a>
        <small>  
             Posted: <time class="published" datetime="2010-09-26T12:10:00-07:00">2010-09-26 12:10</time></small></h1>
        <hr><p></p><p>I was asked, as part of a symposium at the Library of Congress, to speak briefly on the subject of requirements for storing and processing big data, including social media and web datasets.  This post is meant to accompany that talk as a list of references and links.  Some of the thinking here is influenced by <a href="http://www.dataists.com/2010/09/a-taxonomy-of-data-science/">Dataists inaugural post on the topic</a> by Hilary Mason and Chris Wiggins, which itself reminds me a lot of Kernighan and Plauger's book <a href="http://www.amazon.com/Software-Tools-Brian-W-Kernighan/dp/020103669X">Software Tools</a>. </p><p></p> (Disclaimer: in this post I will mention many software products and some companies.  These mentions do not imply any endorsement of those companies or products, but are meant to be illustrative of the state of the art and common usage in the field.)<p></p> What is "big data", anyway?  The generations of yore (like, 20 years ago) measured it in gigabytes.  In 1991, <a href="http://trec.nist.gov/">TREC</a> brought the information retrieval community (the researchers who studied what would come to be called "search engines") from working with megabytes to a two gigabyte text corpus.  This caused tremendous engineering havoc in the research world; we might assume that industrial groups of the time already worked with data an order of magnitude or more larger.  Today's largest web collection made generally available to researchers (at cost! thanks to NSF), <a href="http://boston.lti.cs.cmu.edu/Data/clueweb09/">CLuEWeb09</a>, is 25 terabytes of raw web pages, approximately equivalent to the top tier of a commercial web search engine.  Social media datasets, such as the <a href="http://blogs.loc.gov/loc/2010/04/how-tweet-it-is-library-acquires-entire-twitter-archive/">Twitter archive to be housed at LOC</a>, exist on different scales; the text in such a collection might be a hundreds of gigabytes or a few terabytes, but occupy a graph structure of billions of nodes.<p></p> So the answer is, "big data" is data that's bigger than what you can comfortably store and process right now.  As a comparative, if you've got it, it probably isn't big anymore ("My data is bigger than your data.")  Or, perhaps more realistically, "You thought that was big, wait to see what's coming down the pipe!"<p></p> I won't divide up into sections on storage and processing, because they depend on each other... if you store things in a relational database, that implies certain kinds of processing; if you first think of streaming over data, that implies certain kinds of storage.  My focus is also on what can be done with commodity hardware or cloud resources... I'll try to be up-front about infrastructure costs when I can.  I'm also cheap, so I tend to favor free solutions; the good news in 2010 is that free is as good or better than anything you can pay for, and the next best thing is pretty darn cheap.<p></p> You'd be alarmed at what a modern desktop computer can handle.  A terabyte of hard disk in 2010 costs about $90, plus another $20 if you want it to fit in your laptop.  Two-core processors are now previous-generation; four and eight cores on the desktop are more and more common.  2 GB of RAM is too small for Windows these days, so 4 and 8GB is getting more common.  You can run Windows, Linux, or Mac OS on essentially equivalent hardware, so you can pick the platform you like best.  My experience is in the Unix world, so my perspective is going to center primarily on Linux, Mac OS, or Windows with Cygwin, but that's not a functional requirement of anything here.  This roughly plain-vanilla desktop computer will cost you around $1500-2000 and can handle a terabyte or three of data.<p></p> "Handle" in the context of this article means that you can process the data, slice, dice, and explore it, probably not at interactive speeds, but that you're willing to wait a few minutes or an hour for results.  In the commercial world, the issue is scaling up to serving results in real-time while the data keeps flooding in... I'm not going there right now.<p></p> In the Unix world, the best tools come for free; see the aforementioned Software Tools book for philosophical perspective (but not necessarily freedom).  For the neophyte I recommend <a href="http://www.amazon.com/Think-UNIX-Jon-Lasser/dp/078972376X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1285523360&amp;sr=1-1">Think Unix</a> by Jon Lasser.  Using basic Unix tools, you can<ul><li>reformat your data (sed, awk, perl, tr, and lots more)</li><li>search your data (grep and others)</li><li>cut it into fields (cut, awk)</li><li>transform it in any number of ways (you name it!)</li><li>count occurrences (uniq, nl, grep)</li><li>sort data (sort)</li></ul><p>and do all kinds of exploratory data analysis.  These tools work on plain text files, which is a great simple file format.  They work in a stream fashion, so you can pipe them together to make complex operations.  (My favorite is using "sort | uniq -c | sort -n" to count repeat occurrences, then produce something like a histogram.)  On modern Unixes (i.e., anything you're likely to encounter now), those big text files get cached as you read them and so you can actually scream through data pretty quickly.  This works great for exploring data and trying out ideas without writing or buying a single piece of software, but just using the screwdrivers and wrenches that came with the operating system.</p><p></p> As an example of this usage, I help run a large evaluation in experimental web search.  As part of this, folks send me large ranked lists of documents from the CLuEWeb collection, and I show those web pages to people who decide what's relevant and what's not.  When I get the lists, the documents are keyed by an identifier, but I like to show my users the URL as well since that can be a helpful criterion.  I have a master list of all 1 billion URLs in CLuEWeb with their identifiers, a 50GB text file.  Using just the tools I mentioned above, I can join the identifier lists against the master URL list, and produce my URL lists for my users to review, in a few minutes on my desktop Mac.<p></p> Many of you would point out that this is an obvious job for a relational database, and I might even agree except I'm not such a database person.  However, I could put both the master URL list and the ranked lists I receive into a database and get much the same result from a simple query or two.  Databases seem alarming at first but in reality they're a simple way to store and process data, provided you have a good idea about how to store it from the beginning.  The good news is that you can make bad layout decisions and the database will humor you until you have simply too much data.  As with Unix tools, there are very good free tools, such as <a href="http://www.mysql.com/">MySQL</a> and <a href="http://www.postgresql.org/">PostgreSQL.</a>  There are also expensive commercial solutions, but again, remember the goal here is to explore big data and be a researcher, not to field a commercial realtime solution.  MySQL and PostgreSQL will run just fine on your standard desktop machine and won't cost you a dime.<p></p> Another common idiom for processing big data is to use scripting languages like <a href="http://www.python.org/">Python</a> or <a href="http://www.perl.org/">Perl</a>.  Scripting languages are called that because they didn't used to be compiled; nowadays everything is compiled just-in-time.  The key point is that these languages support rapidly turning a good, complicated idea into a short, fast, reusable computer program.<br> If writing computer programs drove you nuts 10 years ago, come back and give Python a try.  Again, these tools are free and run on any operating system.<p></p>Since I started out saying that if you can hold it in your hand, it isn't big data anymore, I will spend some time talking about how to scale up a storage and processing infrastructure.  Databases do this well for certain kinds of data, but this can be complicated and costly.  The hot idea nowadays is "cloud computing".  Without getting into a buzzword battle, let's call a bunch of equivalent, interchangeable, and anonymous computers working together a cloud.  (Just like a weather cloud is a bunch of equivalent, interchangeable, anonymous droplets of water vapor, working together).  These days you can make your own cloud or rent one.<p></p> I built my own little cloud last year, so I can talk about how this is done.  Each individual computer costs around $1500 and has 8 cores and 8GB of memory.  It also has 8 slots for disks; 8 1.5TB disks costs around $800, so the total cost per computer is $2300.  In cloud parlance, each computer is called a "node".  There is also a certain amount of infrastructure in the form of a computer rack, a network switch, and two uninterruptible power supplies.  A single rack holds 15 nodes, or 15 * 8 * 1.5 = 180 TB of raw disk.<p></p> The key point of cloud computing, in the context of this article, is to keep your data close to the computer doing the work on it.  If your agency or company has a central file store, you are probably aware that your computer has to copy files from the server before you can work on them.  In our little cloud, the idea is that each CPU core is going to work on the data that is sitting on the disks on that machine, and avoid copying things as much as possible.  This way, all the cores can work at the same time without waiting for each other.  This is why my design above has one disk per core per GB of RAM.  (A better system would have 2-4GB of RAM per core; I'm waiting for RAM prices to fall.)<p></p> The common software for computing on a cloud like this is <a href="http://hadoop.apache.org/">Hadoop</a>.  Hadoop includes two key components: a storage infrastucture for making all those disks look like a single disk, and making it reliable; and a programming paradigm called <a href="http://en.wikipedia.org/wiki/MapReduce">Map-Reduce</a>.  Map-Reduce is a style of programming that maximizes letting all those cores work on a part of the problem, then merging the results together easily.  In the Map step, each core gets a piece of the data and can transform it into one or more other pieces of data.  After the Map step, all the data on all the machines gets sorted in parallel so that the data is in order.  The Reduce step, the sorted data are merged together.  This paradigm is extremely flexible and a lot of problems are easy to structure this way.<p></p> One example is indexing a large web crawl.  If you want to search the web, you need to note down all the words in all the web pages, and put them into an index, so that when someone gives you a query with a word, finding the pages that contain that word is fast.  To think about this problem in Map Reduce, imagine that we have a series of web pages, 1 to 1 billion, and each page is a URL and its content.  We'll write this as (URL, content); geeks call that a tuple.  In the Map step, we take each (URL, content) tuple, cut the content into words, and output a series of tuples (word, URL) for each word in the page.  After mapping, these tuples get sorted by word.  The Reduce step collects all the (word, URL) tuples for a single word and outputs the index fragment (word, (URL, URL, ...)), all the URLs for that word.  These get stored someplace where we can easily find them by word.  Voila, search engine.  Well, almost.  The key point is that Map-Reduce automates the splitting up the work and the sorting across a cloud, and gives you a way to think about how to break down problems efficiently in that modality.<p></p> Lots of <a href="http://en.wikipedia.org/wiki/Graph_theory">graph problems</a>, like those that come up in social media, break down the same way.  Graphs in this context are collections of "nodes" and "edges", where edges connect two or more nodes.  Nodes might be people, and edges might be friendship relations.  Edges are tuples in the Map Reduce framework.  Sometimes, a special graph database is called for.  This can help for storing a large graph structure once and automating certain kinds of processing on the graph.  A good graph database, again free, is <a href="http://neo4j.org/">Neo4J</a>.<p></p> A nice Windows tool for graph analytics is <a href="http://nodexl.codeplex.com/">NodeXL</a>.  It runs in Excel and allows exploration of small-to-medium datasets, well, as large as Excel might let you scale.  Its author, Marc Smith, is a prominent figure in social network study.<p></p> The Hadoop ecosystem includes lots of tools for thinking about big data problems as <a href="http://hadoop.apache.org/common/docs/r0.15.2/streaming.html">streams</a>, <a href="http://hbase.apache.org/">databases</a>, <a href="http://hadoop.apache.org/pig/">flow networks</a>, and more.  My favorite tool for statistical analysis is <a href="http://www.r-project.org/">R</a>.  Folks have been working on extending it to Hadoop; I would appreciate some good links on this as I'm not too familiar with this yet.  <p></p> Renting a cloud in many cases makes more sense than building one.  Amazon's <a href="http://aws.amazon.com/elasticmapreduce/">Elastic Map-Reduce</a> allows you to essentially borrow computers at Amazon.com, link them together in a Map Reduce cloud, run your experiment, and store all your data on their cloud-based storage service.  <a href="http://www.rackspace.com/index.php">RackSpace</a> is a company which does managed hosting and will essentially rent you cloud.  Other companies exist; again, the above are not an endorsement but just examples of what people use.<p></p> <span style="text-decoration: underline;">Further reading</span><p></p>Blogs: (others happily included, pls comment)<ul><li><a href="http://www.dataists.com/">Dataists</a> (Hillary Mason of <a href="http://bit.ly">bit.ly</a> and others)</li><li><a href="http://datamining.typepad.com/data_mining/">Text Mining, Visualization, and Social Media</a> (Matt Hurst of Microsoft)</li><li><a href="http://www.cloudera.com/">Cloudera Hadoop and Big Data</a>; Cloudera provides a Hadoop distribution and some glossy-brochure style blog posts</li></ul><p>Academic conferences: (lots of conference are concerned with big data these days... the following are primarily focused on web and social media.  Again, comments appreciated)</p><ul><li><a href="http://icwsm.org/">AAAI International Conference on Weblogs and Social Media (ICWSM)</a>, a venue blending social science, social media, and data science; they also provide some social media datasets for free.</li><li><a href="http://www.wsdm-conference.org/">ACM International Conference on Web Search and Data Mining (WSDM)</a>, a web-oriented big data forum.</li></ul><p>
        <a href="posts/storing-and-processing-big-data.html#disqus_thread" data-disqus-identifier="cache/posts/storing-and-processing-big-data.html">Comments</a>

        </p></div>
        <div class="postbox">
        <h1><a href="posts/new-bass-day-hohner-b2b-headless-bass.html">New Bass Day: Hohner B2B headless bass</a>
        <small>  
             Posted: <time class="published" datetime="2010-09-05T14:11:00-07:00">2010-09-05 14:11</time></small></h1>
        <hr><p></p><p>Well, it actually arrived Friday, but things have been a little busy.</p><p></p> Guitar Center in Avondale, AZ had this used Hohner B2B for sale at a very good price. I called and spoke with Eddie Rojas, who I am singling out for incredible customer service. He got the bass and told me about it over the phone, and emailed me several pictures of the bridge, pickups, and body, which seemed to show generally good condition with maybe some light finish scratches. I agreed to buy it and arranged for shipping. <p></p>  The bass arrived in a guitar box, wrapped and very well packed. And perfect looking. There is one finish blemish on an edge, but otherwise it looks brand new. The photos really highlighted textures in the poly which just aren't there. Tuners were easy to adjust, the strings didn't look too old, generally beautiful.<p></p>  I brought the strings up to tension, tuned it approximately, and left it overnight to settle in. This morning I plugged it up. Details - this is a Steinberger clone and has a licensed Steiny bridge and headpiece, but that's pretty much where the similarity ends. It has a bolt-on maple neck, rosewood fretboard, maple body with a heavy poly finish, passive P-J pickups and VVT pots. Haven't looked at the wiring but I'm not expecting any surprises.<p></p>  The tone through my little amp (Acoustic B20) was very nice, punchy E string, a very light touch. I really like the zero fret... this is my first instrument with one. Open strings sound like fretted notes. Sustain is nice but will undoubtedly be better with the new strings which are on the way. Bought a nice looking string adapter from Ebay so I can use my preferred strings (DR). With the wood construction and passive pickups, it sounds like a straight-up PJ, but is nice and small, easy to travel with, and very light on the shoulder. I find the strap position ok for now, but I tend to play with my bass pretty high up... if you like things low-slung, I can see you might want to build a strap hook to put a button out between frets 12-17.<p></p>  All in all, this is a very nice bass at what was an unbeatable price. I've seen these on the 'bay for 5-700, and the bridge itself would grab $150 at least!<p></p><p> </p><p></p><div class="p_embed p_image_embed"><a href="http://getfile9.posterous.com/getfile/files.posterous.com/pseudo/XqxYRbqyKZNujQMAVcnr8eqh9pcHxc2217wcDKqUjliHXwHcd7aJyH1be9hG/IMG_0164.jpg.scaled.1000.jpg"><img alt="Img_0164" height="667" src="http://getfile8.posterous.com/getfile/files.posterous.com/pseudo/OYX3yTSD34kiDl6LGAZ4AzmOtX7zfh3lVGULmaj0MLhfgmSOpB0x7tXWwvZH/IMG_0164.jpg.scaled.500.jpg" width="500"></a><a href="http://getfile4.posterous.com/getfile/files.posterous.com/pseudo/lNZIep0l6IUXe7V8dUfINfKbblWEgVEmJ2ZCfqlwL0y1EwetzomExvjQcz5K/IMG_0165.jpg.scaled.1000.jpg"><img alt="Img_0165" height="667" src="http://getfile3.posterous.com/getfile/files.posterous.com/pseudo/9QFz98PpCuZT3UKBtQzTKNcg5dRV6K7KiOMVTmcFJktf18E9dHflr2TDBVbd/IMG_0165.jpg.scaled.500.jpg" width="500"></a><a href="http://getfile9.posterous.com/getfile/files.posterous.com/pseudo/WAG3qm96ikiEdiEeGZ7Il4if5kWr2zqIUro1EhGuyQehsVGXTDA6JHYzeAza/IMG_0166.jpg.scaled.1000.jpg"><img alt="Img_0166" height="667" src="http://getfile8.posterous.com/getfile/files.posterous.com/pseudo/SP9GaHMHNsAvm5IhIq1Pszuo6ll0ougrczeUTJSxYeGQG2xjh1XjADY9yH2G/IMG_0166.jpg.scaled.500.jpg" width="500"></a></div>
            
    <p>
        <a href="posts/new-bass-day-hohner-b2b-headless-bass.html#disqus_thread" data-disqus-identifier="cache/posts/new-bass-day-hohner-b2b-headless-bass.html">Comments</a>

        </p></div>
    
<div>
<ul class="pager"><li class="next">
        <a href="index-1.html">Older posts →</a>
</li></ul></div>

    
       <script type="text/javascript">var disqus_shortname="nikolademo";(function(){var a=document.createElement("script");a.async=true;a.type="text/javascript";a.src="http://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)}());</script></div>
    </div>
    <!--End of body content-->
</div>
<div class="footerbox">
    Contents © 2013         <a href="mailto:isoboroff%20at%20gmail">Ian Soboroff</a> - Powered by         <a href="http://nikola.ralsina.com.ar">Nikola</a>
</div>

    <!-- Social buttons -->
    <div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
    <a class="addthis_button_more">Share</a>
    <ul><li><a class="addthis_button_facebook"></a>
    </li><li><a class="addthis_button_google_plusone_share"></a>
    </li><li><a class="addthis_button_linkedin"></a>
    </li><li><a class="addthis_button_twitter"></a>
    </li></ul></div>
    <script type="text/javascript" src="http://s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script><!-- End of social buttons --><script src="assets/js/jquery-1.7.2.min.js" type="text/javascript"></script><script src="assets/js/bootstrap.min.js" type="text/javascript"></script><script src="assets/js/jquery.colorbox-min.js" type="text/javascript"></script><script type="text/javascript">jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"80%",maxHeight:"80%",scalePhotos:true});</script></body></html>